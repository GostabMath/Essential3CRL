{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1eec4d70-88bf-4ce2-b1a8-1e267babf051",
   "metadata": {},
   "source": [
    "## Personal Project:Counterfactual evaluation with Causal-Design Recommendation Systems\n",
    "\n",
    "### Introduction\n",
    " This is a project extension for David Rosenberg. \n",
    " \n",
    " we're going to be reproducing a few results from http://proceedings.mlr.press/v97/vlassis19a.html, and extending their results in a few ways.  Here's an overview: We start by taking a multiclass classification problem and splitting it into train and test.  There are 26 classes, which we'll interpret as 26 possible actions to take for every input context. On the training set, we fit a multinomial logistic regression model to predict the correct label/best action.  Following the paper, we create a logging policy based on this model (details supplied in the relevant spot below).  We then generate \"logged bandit feedback\" for this logging policy using the **test** set.  Given this logged bandit feedback, we'll try out several different methods for estimating the value of various policies.  We'll also estimate the value of each of these policies using the full-feedback (i.e. the full observed rewards), and we'll treat that as the ground truth value for the purpose of performance assessment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a9661661-6ece-47fd-b483-bf6481b2f854",
   "metadata": {},
   "source": [
    "### Pre-setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5e0fb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0791e0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_integer_dtype\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "from scipy.special import expit\n",
    "import seaborn as sns\n",
    "import warnings;\n",
    "warnings.filterwarnings('ignore');\n",
    "import sys\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6203c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c22d10e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fully_observed_bandit():\n",
    "    \"\"\"\n",
    "    This loads in a multiclass classification problem and reformulates it as a fully observed bandit problem.\n",
    "    \n",
    "    \"\"\"\n",
    "    df_l = pd.read_csv('letter-recognition.data',\n",
    "                       names = ['a']+[f'x{i}' for i in range(16)])\n",
    "    X = df_l.drop(columns=['a'])\n",
    "\n",
    "    # Convert labels to ints and one-hot\n",
    "    y = df_l['a']\n",
    "    # if y is not column of integers (that represent classes), then convert\n",
    "    if not is_integer_dtype(y.dtype):\n",
    "        y = y.astype('category').cat.codes\n",
    "\n",
    "    ## Full rewards\n",
    "    n = len(y)\n",
    "    k = max(y)+1\n",
    "    full_rewards = np.zeros([n, k])# return an array that follows the shape of[nrow,kcol]\n",
    "    full_rewards[np.arange(0,n),y] = 1\n",
    "    contexts = X\n",
    "    best_actions = y\n",
    "    return contexts, full_rewards, best_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4132ca6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a temporary view of Data.\n",
    "df_1_c= pd.read_csv('letter-recognition.data',\n",
    "                       names = ['a']+[f'x{i}' for i in range(16)]) # create the the ordered cols following the context index 1-16; using function\"f\"\n",
    "df_1_c\n",
    "yc = df_1_c['a'].astype('category').cat.codes\n",
    "v_rewards = np.zeros([len(yc),max(yc)+1])\n",
    "v_rewards[np.arange(0,len(yc)),yc]=1 # np.arange is to generate an array starting with a and stopping with b\n",
    "v_rewards\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2afd69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 26 actions, the context space is 16 dimensional, and there are 20000 examples.\n",
      "For example, the first item has context vector:\n",
      "   x0  x1  x2  x3  x4  x5  x6  x7  x8  x9  x10  x11  x12  x13  x14  x15\n",
      "0   2   8   3   5   1   8  13   0   6   6   10    8    0    8    0    8.\n",
      "The best action is 19.  The reward for that action is 1 and all other actions get reward 0.\n",
      "The reward information is store in full_rewards as the row\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0.].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(       x0  x1  x2  x3  x4  x5  x6  x7  x8  x9  x10  x11  x12  x13  x14  x15\n",
       " 0       2   8   3   5   1   8  13   0   6   6   10    8    0    8    0    8\n",
       " 1       5  12   3   7   2  10   5   5   4  13    3    9    2    8    4   10\n",
       " 2       4  11   6   8   6  10   6   2   6  10    3    7    3    7    3    9\n",
       " 3       7  11   6   6   3   5   9   4   6   4    4   10    6   10    2    8\n",
       " 4       2   1   3   1   1   8   6   6   6   6    5    9    1    7    5   10\n",
       " ...    ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...  ...\n",
       " 19995   2   2   3   3   2   7   7   7   6   6    6    4    2    8    3    7\n",
       " 19996   7  10   8   8   4   4   8   6   9  12    9   13    2    9    3    7\n",
       " 19997   6   9   6   7   5   6  11   3   7  11    9    5    2   12    2    4\n",
       " 19998   2   3   4   2   1   8   7   2   6  10    6    8    1    9    5    8\n",
       " 19999   4   9   6   6   2   9   5   3   1   8    1    8    2    7    2    8\n",
       " \n",
       " [20000 rows x 16 columns],\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]]),\n",
       " 0        19\n",
       " 1         8\n",
       " 2         3\n",
       " 3        13\n",
       " 4         6\n",
       "          ..\n",
       " 19995     3\n",
       " 19996     2\n",
       " 19997    19\n",
       " 19998    18\n",
       " 19999     0\n",
       " Length: 20000, dtype: int8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts, full_rewards, best_actions = get_fully_observed_bandit()\n",
    "n, k = full_rewards.shape\n",
    "_, d = contexts.shape\n",
    "print(f\"There are {k} actions, the context space is {d} dimensional, and there are {n} examples.\")\n",
    "print(f\"For example, the first item has context vector:\\n{contexts.iloc[0:1]}.\")\n",
    "print(f\"The best action is {best_actions[0]}.  The reward for that action is 1 and all other actions get reward 0.\")\n",
    "print(f\"The reward information is store in full_rewards as the row\\n{full_rewards[0]}.\")\n",
    "get_fully_observed_bandit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59ba6ba4-b43c-4447-9465-35ae762cb65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choose train/test indices\n",
    "rng = default_rng(7)\n",
    "train_frac = 0.5\n",
    "train_size = round(train_frac * n)\n",
    "train_idx = rng.choice(n, size = train_size, replace = False)# this command is used to randomly select a fixed number of observations\n",
    "test_idx = np.setdiff1d(np.arange(n), train_idx, assume_unique=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c79f497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P0</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>P5</th>\n",
       "      <th>P6</th>\n",
       "      <th>P7</th>\n",
       "      <th>P8</th>\n",
       "      <th>P9</th>\n",
       "      <th>...</th>\n",
       "      <th>Con7</th>\n",
       "      <th>Con8</th>\n",
       "      <th>Con9</th>\n",
       "      <th>Con10</th>\n",
       "      <th>Con11</th>\n",
       "      <th>Con12</th>\n",
       "      <th>Con13</th>\n",
       "      <th>Con14</th>\n",
       "      <th>Con15</th>\n",
       "      <th>ActionTaken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        P0   P1   P2   P3   P4   P5   P6   P7   P8   P9  ...  Con7  Con8  \\\n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   6.0   \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  ...   5.0   4.0   \n",
       "2      0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   2.0   6.0   \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   4.0   6.0   \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...   6.0   6.0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   \n",
       "19995  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   7.0   6.0   \n",
       "19996  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   6.0   9.0   \n",
       "19997  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   3.0   7.0   \n",
       "19998  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   2.0   6.0   \n",
       "19999  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   3.0   1.0   \n",
       "\n",
       "       Con9  Con10  Con11  Con12  Con13  Con14  Con15  ActionTaken  \n",
       "0       6.0   10.0    8.0    0.0    8.0    0.0    8.0           19  \n",
       "1      13.0    3.0    9.0    2.0    8.0    4.0   10.0            8  \n",
       "2      10.0    3.0    7.0    3.0    7.0    3.0    9.0            3  \n",
       "3       4.0    4.0   10.0    6.0   10.0    2.0    8.0           13  \n",
       "4       6.0    5.0    9.0    1.0    7.0    5.0   10.0            6  \n",
       "...     ...    ...    ...    ...    ...    ...    ...          ...  \n",
       "19995   6.0    6.0    4.0    2.0    8.0    3.0    7.0            3  \n",
       "19996  12.0    9.0   13.0    2.0    9.0    3.0    7.0            2  \n",
       "19997  11.0    9.0    5.0    2.0   12.0    2.0    4.0           19  \n",
       "19998  10.0    6.0    8.0    1.0    9.0    5.0    8.0           18  \n",
       "19999   8.0    1.0    8.0    2.0    7.0    2.0    8.0            0  \n",
       "\n",
       "[20000 rows x 43 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_policy = [f\"P{x}\" for x in range(26)] #this is to generate similar column names\n",
    "name_contexts = [f\"Con{i}\" for i in range(16)]\n",
    "df_f = pd.DataFrame(np.concatenate((full_rewards,contexts),axis=1 ),columns=name_policy+name_contexts)\n",
    "df_f['ActionTaken']=best_actions\n",
    "df_f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4aa0f30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.array(contexts)[[2],[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a87ea1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 26)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m=(df_f.iloc[:,1:17].melt())\n",
    "df_m[df_m[\"value\"]==1].sort_index\n",
    "psm1 = LogisticRegression(multi_class=\"multinomial\")\n",
    "fpsm = psm1.fit(contexts,best_actions)\n",
    "ps=psm1.predict_proba(contexts)\n",
    "#ps = pd.DataFrame(fpsm,columns=[f\"a{i}\" for i in range(16)])\n",
    "ps_var = [f\"A{r}\" for r in range(26)]\n",
    "ps_df = pd.DataFrame(data= ps,dtype=float, columns=ps_var)\n",
    "ps_df = ps_df.round(6)\n",
    "#a = [ps_df.iloc[[i],[v]]for i in ps_df.shape[0], for v in ps_df.shape(1) if ]\n",
    "ps_df['ActionTaken']=best_actions\n",
    "ps_df[\"Chosen\"]=ps[range(best_actions.shape[0]),best_actions]\n",
    "type(ps_df)\n",
    "ps_df\n",
    "ps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bcb802c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "924c67ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>x14</th>\n",
       "      <th>x15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x0  x1  x2  x3  x4  x5  x6  x7  x8  x9  x10  x11  x12  x13  x14  x15\n",
       "1   5  12   3   7   2  10   5   5   4  13    3    9    2    8    4   10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts.iloc[[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23b011d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "r= np.array(full_rewards)\n",
    "trial = [np.inner(r[[i]],ps[[i]]) for i in range(contexts.shape[0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27b872d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6200568740371194"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c958da83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19, 16,  9, ..., 19, 18,  0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([rng.choice(26,p=p) for p in ps])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b701487d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c106ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#incorrect function for corresponding probability\n",
    "def corres_prob(propMatrix,action):\n",
    "    p= pd.DataFrame()\n",
    "    n = propMatrix.shape[0]\n",
    "    m = best_actions.shape[0]\n",
    "    k = propMatrix.shape[1]\n",
    "    for i,j in [[i,j]for i in range(n) for j in range(m)]:\n",
    "            a=[propMatrix[[i],[x]] for x in range(k) if np.array(x) == action[[j],:]]\n",
    "        \n",
    "    p[\"cor_p\"]=a\n",
    "    return(p)\n",
    "corres_prob(propMatrix=ps_df,action=best_actions)\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2952bcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "90637368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05,\n",
       " 0.05]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1/20]*20\n",
    "a"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2fd5649-06c5-4993-8c84-c043586ade18",
   "metadata": {},
   "source": [
    "### Policies\n",
    "In this section, we'll build out a Policy class, some specific policies, and evaluate policies on full-feedback data.\n",
    "\n",
    "**Class Writing for Policy Evaluation** We will complete the Policy class and the UniformActionPolicy classes below. Run the code provided to get an estimate of the value of the uniform action policy using the test set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d36a4b2d-9440-4c52-b0ec-502b4ce6cd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy:\n",
    "    def __init__(self, num_actions=2):\n",
    "        self.num_actions = num_actions\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_action_distribution(self, X):\n",
    "        \"\"\"   \n",
    "        This method is intended to be overridden by each implementation of Policy.\n",
    "\n",
    "        Args:\n",
    "            X (pd.DataFrame): context\n",
    "\n",
    "        Returns:\n",
    "            2-dim numpy array with the same number of rows as X and self.num_actions columns. \n",
    "                Each rows gives the policy's probability distribution over actions conditioned on the context in the corresponding row of X\n",
    "        \"\"\"   \n",
    "        raise NotImplementedError(\"Must override method\")\n",
    "\n",
    "    def get_action_propensities(self, X, actions):\n",
    "        \"\"\"   \n",
    "        Args:\n",
    "            X (pd.DataFrame): contexts, rows correspond to entries of actions\n",
    "            actions (np.array): actions taken, represented by integers, corresponding to rows of X\n",
    "\n",
    "        Returns:\n",
    "            1-dim numpy array of probabilities (same size as actions) for taking each action in its corresponding context\n",
    "        \"\"\"   \n",
    "        \n",
    "        prop = self.get_action_distribution(X)\n",
    "        prop_chosen = prop[range(X.shape[0]),actions]\n",
    "        return prop_chosen\n",
    "        \n",
    "        \n",
    " \n",
    "    def select_actions(self, X,rng=default_rng(1)):\n",
    "        \"\"\"   \n",
    "        Args:\n",
    "            X (pd.DataFrame): contexts, rows correspond to entries of actions and propensities returned\n",
    "\n",
    "        Returns:\n",
    "            actions (np.array): 1-dim numpy array of length equal to the number of rows of X.  Each entry is an integer indicating the action selected for the corresponding context in X. \n",
    "                The action is selected randomly according to the policy, conditional on the context specified in the appropriate row of X.\n",
    "            propensities (np.array): 1-dim numpy array of length equal to the number of rows of X; gives the propensity for each action selected in actions\n",
    "\n",
    "        \"\"\"\n",
    "        prop= self.get_action_distribution(X)\n",
    "        action_chosen = np.array([rng.choice(26,p=p)for p in prop])\n",
    "        prop_chosen = prop[range(action_chosen.shape[0]),action_chosen]\n",
    "        return action_chosen, prop_chosen\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    def get_value_estimate(self, X, full_rewards):\n",
    "        \"\"\"   \n",
    "        Args:\n",
    "            X (pd.DataFrame): contexts, rows correspond to entries of full_rewards\n",
    "            full_rewards (np.array): 2-dim numpy array with the same number of rows as X and self.num_actions columns; \n",
    "                each row gives the rewards that would be received for each action for the context in the corresponding row of X.\n",
    "                This would only be known in a full-feedback bandit, or estimated in a direct method\n",
    "\n",
    "        Returns:\n",
    "            scalar value giving the expected average reward received for playing the policy for contexts X and the given full_rewards\n",
    "\n",
    "        \"\"\"   \n",
    "        \n",
    "        prop = self.get_action_distribution(X)\n",
    "        #unit_estimate = np.multiply(full_rewards[range(prop_chosen.shape[0]),action_chosen],prop_chosen)\n",
    "        unit_estimate= [np.inner(np.array(full_rewards)[[i]],prop[[i]]) for i in range(full_rewards.shape[0])]\n",
    "        reward_est = np.mean(unit_estimate)\n",
    "        return reward_est\n",
    "\n",
    "class UniformActionPolicy(Policy): \n",
    "    def __init__(self, num_actions=2):\n",
    "        self.num_actions = num_actions\n",
    "\n",
    "    def get_action_distribution(self, X):\n",
    "        unit_prop = np.array([[1/self.num_actions]*self.num_actions])\n",
    "        uniform_prop = unit_prop.repeat(X.shape[0],axis=0)\n",
    "        \n",
    "        return uniform_prop\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "efa4a5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U0</th>\n",
       "      <th>U1</th>\n",
       "      <th>U2</th>\n",
       "      <th>U3</th>\n",
       "      <th>U4</th>\n",
       "      <th>U5</th>\n",
       "      <th>U6</th>\n",
       "      <th>U7</th>\n",
       "      <th>U8</th>\n",
       "      <th>U9</th>\n",
       "      <th>...</th>\n",
       "      <th>U16</th>\n",
       "      <th>U17</th>\n",
       "      <th>U18</th>\n",
       "      <th>U19</th>\n",
       "      <th>U20</th>\n",
       "      <th>U21</th>\n",
       "      <th>U22</th>\n",
       "      <th>U23</th>\n",
       "      <th>U24</th>\n",
       "      <th>U25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             U0        U1        U2        U3        U4        U5        U6  \\\n",
       "0      0.038462  0.038462  0.038462  0.038462  0.038462  0.038462  0.038462   \n",
       "1      0.038462  0.038462  0.038462  0.038462  0.038462  0.038462  0.038462   \n",
       "2      0.038462  0.038462  0.038462  0.038462  0.038462  0.038462  0.038462   \n",
       "3      0.038462  0.038462  0.038462  0.038462  0.038462  0.038462  0.038462   \n",
       "4      0.038462  0.038462  0.038462  0.038462  0.038462  0.038462  0.038462   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "19995  0.038462  0.038462  0.038462  0.038462  0.038462  0.038462  0.038462   \n",
       "19996  0.038462  0.038462  0.038462  0.038462  0.038462  0.038462  0.038462   \n",
       "19997  0.038462  0.038462  0.038462  0.038462  0.038462  0.038462  0.038462   \n",
       "19998  0.038462  0.038462  0.038462  0.038462  0.038462  0.038462  0.038462   \n",
       "19999  0.038462  0.038462  0.038462  0.038462  0.038462  0.038462  0.038462   \n",
       "\n",
       "             U7        U8        U9  ...       U16       U17       U18  \\\n",
       "0      0.038462  0.038462  0.038462  ...  0.038462  0.038462  0.038462   \n",
       "1      0.038462  0.038462  0.038462  ...  0.038462  0.038462  0.038462   \n",
       "2      0.038462  0.038462  0.038462  ...  0.038462  0.038462  0.038462   \n",
       "3      0.038462  0.038462  0.038462  ...  0.038462  0.038462  0.038462   \n",
       "4      0.038462  0.038462  0.038462  ...  0.038462  0.038462  0.038462   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "19995  0.038462  0.038462  0.038462  ...  0.038462  0.038462  0.038462   \n",
       "19996  0.038462  0.038462  0.038462  ...  0.038462  0.038462  0.038462   \n",
       "19997  0.038462  0.038462  0.038462  ...  0.038462  0.038462  0.038462   \n",
       "19998  0.038462  0.038462  0.038462  ...  0.038462  0.038462  0.038462   \n",
       "19999  0.038462  0.038462  0.038462  ...  0.038462  0.038462  0.038462   \n",
       "\n",
       "            U19       U20       U21       U22       U23       U24       U25  \n",
       "0      0.038462  0.038462  0.038462  0.038462  0.038462  0.038462  0.038462  \n",
       "1      0.038462  0.038462  0.038462  0.038462  0.038462  0.038462  0.038462  \n",
       "2      0.038462  0.038462  0.038462  0.038462  0.038462  0.038462  0.038462  \n",
       "3      0.038462  0.038462  0.038462  0.038462  0.038462  0.038462  0.038462  \n",
       "4      0.038462  0.038462  0.038462  0.038462  0.038462  0.038462  0.038462  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "19995  0.038462  0.038462  0.038462  0.038462  0.038462  0.038462  0.038462  \n",
       "19996  0.038462  0.038462  0.038462  0.038462  0.038462  0.038462  0.038462  \n",
       "19997  0.038462  0.038462  0.038462  0.038462  0.038462  0.038462  0.038462  \n",
       "19998  0.038462  0.038462  0.038462  0.038462  0.038462  0.038462  0.038462  \n",
       "19999  0.038462  0.038462  0.038462  0.038462  0.038462  0.038462  0.038462  \n",
       "\n",
       "[20000 rows x 26 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniform_test = UniformActionPolicy(num_actions=k)\n",
    "unif_plc = uniform_test.get_action_distribution(X=contexts)\n",
    "unif_plc\n",
    "dic_index = [f\"U{i}\" for i in range(k)]\n",
    "dic_fm = pd.DataFrame(data=unif_plc,columns=dic_index)\n",
    "dic_fm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d3415c8",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85bd1c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = contexts.iloc[train_idx].to_numpy()\n",
    "y_train = best_actions.iloc[train_idx].to_numpy()\n",
    "X_test = contexts.iloc[test_idx].to_numpy()\n",
    "y_test = best_actions.iloc[test_idx].to_numpy()\n",
    "full_rewards_test = full_rewards[test_idx]\n",
    "uniform_policy = UniformActionPolicy(num_actions=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b9716f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19, 18,  6, ...,  5, 22, 19])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generic_policy=Policy(num_actions=k)\n",
    "display_distribution = generic_policy.select_actions(X=X_test,actions=y_test)\n",
    "display_distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e49733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6287a4e1-c413-4694-88ba-c086799496da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimate of the value of the uniform action policy using the full-feedback test set is 0.03846153846153845.\n"
     ]
    }
   ],
   "source": [
    "uniform_policy_value = uniform_policy.get_value_estimate(X=X_test, full_rewards=full_rewards_test)\n",
    "print(f\"The estimate of the value of the uniform action policy using the full-feedback test set is {uniform_policy_value}.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c85bfc2-b9e3-4704-ac2c-24d7f8e5d7d7",
   "metadata": {},
   "source": [
    "**Problem 2.**  Complete the SKLearnPolicy class below and run the code that creates two policies and estimates their values using the full reward information in the test set.  You should find that the deterministic policy has a higher value than the stochastic policy.  Nevertheless, why might one choose to deploy the stochastic policy rather than the deterministic policy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bfa0a7c0-8186-47e3-bc59-d838c30b9df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic policy true value 0.7631.\n",
      "Deterministic policy true value 0.6261601176972126.\n"
     ]
    }
   ],
   "source": [
    "class SKLearnPolicy(Policy):\n",
    "    \"\"\" \n",
    "    An SKLearnPolicy uses a scikit learn model to generate an action distribution.  If the SKLearnPolicy is built with is_deterministic=False, \n",
    "    then the action distribution for a context x should be whatever predict_proba for the model returns.  If is_deterministic=True, then all the probability mass \n",
    "    should be concentrated on whatever predict of the model returns.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, num_actions=2, is_deterministic=False):\n",
    "        self.is_deterministic = is_deterministic\n",
    "        self.num_actions = num_actions\n",
    "        self.model = model\n",
    "\n",
    "    def get_action_distribution(self, X):\n",
    "        \n",
    "        if (self.is_deterministic):\n",
    "        \n",
    "         propensity = model.predict_proba(X)\n",
    "         return propensity\n",
    "        \n",
    "    \n",
    "        else:\n",
    "         pred_action = model.predict(X)\n",
    "         blank = np.zeros([X.shape[0],self.num_actions])\n",
    "         blank[range(X.shape[0]),pred_action]=1\n",
    "         propensity = blank\n",
    "         \n",
    "         return propensity\n",
    "\n",
    "        \n",
    "\n",
    "    def select_actions(self, X, rng=default_rng(1)):\n",
    "        \"\"\" You don't technically have to override this function.  If you just delete this function, the parent class Policy can handle it in a generic way\n",
    "        However, if is_deterministic=True, then the action distribution for each context is trivial -- it always puts probability one for a \n",
    "        particular action and 0 for the others. And so \"randomly\" selecting an action according to this distribution using the code you write\n",
    "        for select_actions in the parent class (Policy) is very inefficient.  You can just use model.predict to get the actions that will be \n",
    "        selected for each context.  That's the idea of the if statement.\"\"\"\n",
    "        \n",
    "       \n",
    "          \n",
    "             \n",
    "        if (self.is_deterministic):\n",
    "          propensity = self.get_action_distribution(X)\n",
    "          chosen_actions = np.array([rng.choice(26, p =p) for p in propensity])\n",
    "          chosen_prop = propensity[range(chosen_actions.shape[0]),chosen_actions]\n",
    "          \n",
    "          return chosen_actions,chosen_prop\n",
    "        \n",
    "        else:\n",
    "          chosen_actions = model.predict(X)\n",
    "          chosen_prop = np.array([1]*X.shape[0]).T\n",
    "          return chosen_actions,chosen_prop\n",
    "        \n",
    "        \n",
    "\n",
    "model = LogisticRegression(multi_class='multinomial')\n",
    "model.fit(X_train, y_train)\n",
    "policy_stochastic = SKLearnPolicy(model=model, num_actions=k, is_deterministic=False)\n",
    "policy_deterministic = SKLearnPolicy(model=model, num_actions=k, is_deterministic=True)\n",
    "\n",
    "policy_stochastic_true_value = policy_stochastic.get_value_estimate(X_test, full_rewards_test)\n",
    "policy_deterministic_true_value = policy_deterministic.get_value_estimate(X_test, full_rewards_test)\n",
    "print(f\"Stochastic policy true value {policy_stochastic_true_value}.\")\n",
    "print(f\"Deterministic policy true value {policy_deterministic_true_value}.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b30e36f-4138-4c30-af2a-1e62f5dd3deb",
   "metadata": {},
   "source": [
    "**Problem 3.** Fill in the VlassisLoggingPolicy class below, and evaluate the value of this logging policy using the code provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "041029e4-da4d-498f-90d8-aa53e2350578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimate of the value of the logging policy using the full-feedback test set is 0.0471572.\n"
     ]
    }
   ],
   "source": [
    "class VlassisLoggingPolicy(Policy):\n",
    "    \"\"\"\n",
    "    This policy derives from another deterministic policy following the recipe described in the Vlassis et al paper, on the top of the second column in section 5.3.\n",
    "    For any context x, if the deterministic policy selects action a, then this policy selects action a with probability eps (a supplied parameter), and spreads the\n",
    "    rest of the probability mass uniformly over the other actions.\n",
    "    \"\"\"\n",
    "    def __init__(self, deterministic_target_policy, num_actions=2, eps=0.05,):\n",
    "        self.num_actions = num_actions\n",
    "        self.target_policy = deterministic_target_policy\n",
    "        self.eps = eps\n",
    "\n",
    "    def get_action_distribution(self, X):\n",
    "        blank = np.zeros([X.shape[0],self.num_actions])\n",
    "        predicted_actions = model.predict(X)\n",
    "        blank[range(X.shape[0]),predicted_actions]=self.eps\n",
    "        blank[blank==0]=(1-self.eps)/25\n",
    "        propensity = blank\n",
    "        \n",
    "\n",
    "        return propensity\n",
    "        \n",
    "    \n",
    "logging_policy = VlassisLoggingPolicy(policy_deterministic, num_actions=k, eps=0.05)\n",
    "logging_policy_value = logging_policy.get_value_estimate(X=X_test, full_rewards=full_rewards_test)\n",
    "print(f\"The estimate of the value of the logging policy using the full-feedback test set is {logging_policy_value}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2aaea235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A0</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>...</th>\n",
       "      <th>A16</th>\n",
       "      <th>A17</th>\n",
       "      <th>A18</th>\n",
       "      <th>A19</th>\n",
       "      <th>A20</th>\n",
       "      <th>A21</th>\n",
       "      <th>A22</th>\n",
       "      <th>A23</th>\n",
       "      <th>A24</th>\n",
       "      <th>A25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.038</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.050</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         A0     A1     A2     A3     A4     A5     A6     A7     A8     A9  \\\n",
       "0     0.038  0.038  0.038  0.038  0.038  0.038  0.038  0.038  0.038  0.038   \n",
       "1     0.038  0.038  0.038  0.038  0.038  0.038  0.038  0.038  0.050  0.038   \n",
       "2     0.038  0.038  0.038  0.038  0.038  0.038  0.050  0.038  0.038  0.038   \n",
       "3     0.038  0.050  0.038  0.038  0.038  0.038  0.038  0.038  0.038  0.038   \n",
       "4     0.050  0.038  0.038  0.038  0.038  0.038  0.038  0.038  0.038  0.038   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "9995  0.038  0.038  0.038  0.038  0.038  0.050  0.038  0.038  0.038  0.038   \n",
       "9996  0.038  0.038  0.038  0.038  0.038  0.038  0.038  0.038  0.038  0.038   \n",
       "9997  0.038  0.038  0.038  0.038  0.038  0.050  0.038  0.038  0.038  0.038   \n",
       "9998  0.038  0.038  0.038  0.038  0.038  0.038  0.038  0.038  0.038  0.038   \n",
       "9999  0.038  0.038  0.038  0.038  0.038  0.038  0.038  0.038  0.038  0.038   \n",
       "\n",
       "      ...    A16    A17    A18    A19    A20    A21    A22    A23    A24  \\\n",
       "0     ...  0.038  0.038  0.038  0.050  0.038  0.038  0.038  0.038  0.038   \n",
       "1     ...  0.038  0.038  0.038  0.038  0.038  0.038  0.038  0.038  0.038   \n",
       "2     ...  0.038  0.038  0.038  0.038  0.038  0.038  0.038  0.038  0.038   \n",
       "3     ...  0.038  0.038  0.038  0.038  0.038  0.038  0.038  0.038  0.038   \n",
       "4     ...  0.038  0.038  0.038  0.038  0.038  0.038  0.038  0.038  0.038   \n",
       "...   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "9995  ...  0.038  0.038  0.038  0.038  0.038  0.038  0.038  0.038  0.038   \n",
       "9996  ...  0.038  0.038  0.038  0.038  0.038  0.038  0.038  0.038  0.038   \n",
       "9997  ...  0.038  0.038  0.038  0.038  0.038  0.038  0.038  0.038  0.038   \n",
       "9998  ...  0.038  0.038  0.038  0.038  0.038  0.038  0.050  0.038  0.038   \n",
       "9999  ...  0.038  0.038  0.038  0.050  0.038  0.038  0.038  0.038  0.038   \n",
       "\n",
       "        A25  \n",
       "0     0.038  \n",
       "1     0.038  \n",
       "2     0.038  \n",
       "3     0.038  \n",
       "4     0.038  \n",
       "...     ...  \n",
       "9995  0.038  \n",
       "9996  0.038  \n",
       "9997  0.038  \n",
       "9998  0.038  \n",
       "9999  0.038  \n",
       "\n",
       "[10000 rows x 26 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = VlassisLoggingPolicy(policy_deterministic,num_actions=k, eps=0.05)\n",
    "a= test.get_action_distribution(X=X_test)\n",
    "a = pd.DataFrame(a,columns=[f\"A{i}\" for i in range(26)])\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3652c51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d606843e-58ec-481f-a04b-d8deced26f4e",
   "metadata": {},
   "source": [
    "### Simulate bandit feedback and on-policy evaluation\n",
    "**Problem 4.** Take a look at the generate_bandit_feedback function, so you understand how it works.  Then generate bandit feedback using the test data -- generate as many rounds are there are contexts in the test data. Use the result to generate an \"on-policy\" estimate of the value of the logging policy.  How does it compare to our \"ground truth\" estimate you found previously using the full-feedback test set? Repeat using 1/100th, 1/10th, and 10x as much bandit feedback, to see how much the value estimates change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fcb89039-c4f1-4ff7-9957-d6fded9a7b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bandit_feedback(contexts, full_rewards, policy,\n",
    "                             new_n = None,\n",
    "                             rng=default_rng(1)):\n",
    "    \"\"\"   \n",
    "    Args:\n",
    "        contexts (np.array): contexts, rows correspond to entries of rewards\n",
    "        full_rewards (np.array): 2-dim numpy array with the same number of rows as X and number of columns corresponding to the number actions\n",
    "            each row gives the reward that would be received for each action for the context in the corresponding row of X. \n",
    "\n",
    "    Returns:\n",
    "        new_contexts (np.array): new_n rows and same number of columns as in contexts\n",
    "        actions (np.array): vector with new_n entries giving actions selected by the provided policy for the contexts in new_contexts\n",
    "        observed_rewards (np.array): vector with new_n entries giving rewards received for the actions taken (in actions) in each context of new_contexts \n",
    "    \"\"\"   \n",
    "    \n",
    "    if new_n is None:\n",
    "        new_n = contexts.shape[0]\n",
    "    n, k = full_rewards.shape\n",
    "    num_repeats = np.ceil(new_n / n).astype(int)\n",
    "    new_contexts = np.tile(contexts, [num_repeats,1])\n",
    "    new_contexts = new_contexts[0:new_n]\n",
    "    new_rewards = np.tile(full_rewards, [num_repeats,1])\n",
    "    new_rewards = new_rewards[0:new_n]\n",
    "    actions, propensities = policy.select_actions(X=new_contexts, rng=rng)\n",
    "    observed_rewards = new_rewards[np.arange(new_n), actions]\n",
    "    return new_contexts, actions, observed_rewards, propensities\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f68f57bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>X12</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>X15</th>\n",
       "      <th>Action Observed</th>\n",
       "      <th>Reward Observed</th>\n",
       "      <th>Propensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.960960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.447682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.819207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.839590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.569896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.561289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.876559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.958187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.958269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      X0  X1  X2  X3  X4  X5  X6  X7  X8  X9  X10  X11  X12  X13  X14  X15  \\\n",
       "0      2   8   3   5   1   8  13   0   6   6   10    8    0    8    0    8   \n",
       "1      5  12   3   7   2  10   5   5   4  13    3    9    2    8    4   10   \n",
       "2      2   1   3   1   1   8   6   6   6   6    5    9    1    7    5   10   \n",
       "3      4   2   5   4   4   8   7   6   6   7    6    6    2    8    7   10   \n",
       "4      1   1   3   2   1   8   2   2   2   8    2    8    1    6    2    7   \n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...  ...   \n",
       "9995   6  12   6   7   3   6   8   3   6  13    7    7    2    9    3    7   \n",
       "9996   7  10   5   5   2   6  11   5   4  11    9    4    4   11    3   10   \n",
       "9997   2   1   3   2   1   4  10   3   5  10    8    5    0    9    3    7   \n",
       "9998   3   8   5   6   5  11  11   2   2   5    8    7    7   12    1    7   \n",
       "9999   6   9   6   7   5   6  11   3   7  11    9    5    2   12    2    4   \n",
       "\n",
       "      Action Observed  Reward Observed  Propensity  \n",
       "0                  19              1.0    0.960960  \n",
       "1                   8              1.0    0.447682  \n",
       "2                  16              0.0    0.232234  \n",
       "3                   1              1.0    0.819207  \n",
       "4                   0              1.0    0.839590  \n",
       "...               ...              ...         ...  \n",
       "9995                5              0.0    0.569896  \n",
       "9996               15              0.0    0.561289  \n",
       "9997                5              0.0    0.876559  \n",
       "9998               22              1.0    0.958187  \n",
       "9999               19              1.0    0.958269  \n",
       "\n",
       "[10000 rows x 19 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b,c,d=generate_bandit_feedback(contexts = X_test,full_rewards=full_rewards_test,policy=policy_deterministic, new_n =None ,rng=default_rng(2))\n",
    "View = pd.DataFrame(data=a, columns=[f\"X{i}\" for i in range(16)])\n",
    "View[\"Action Observed\"]=b\n",
    "View[\"Reward Observed\"]=c\n",
    "View[\"Propensity\"] = d\n",
    "View\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6829a2bc-4cad-4b46-be89-ea68450c3c65",
   "metadata": {},
   "source": [
    "### Test out off-policy value estimators\n",
    "**This is the final research question and the foundation of more advanced methods for Causal-based Recommendation Systems targeting Counterfactual Learning** \n",
    "\n",
    "we will complete the get_value_estimators function below, per the specification.  Include the following estimators\n",
    "- Unweighted mean (**matching the complete estimator in counterfactuals**)\n",
    "- Importance-weighted (IW) value estimator(**MAR Situation**)\n",
    "- Self-normalized IW mean(**Reducing the variance of estimator in MAR missing data setting**)\n",
    "- Direct method with linear ridge regression reward predictor fit for each action\n",
    "- Direct method with IW-linear ridge regression reward predictor fit for each action\n",
    "- [**Testing for properties of this estimator**] Direct method with a non-linear reward predictor fit for each action\n",
    "- [**think: Does Causal Forest work well/Recursive Partitioning**] Direct method with a non-linear reward predictor fit for all actions at once (action becomes part of the input)\n",
    "\n",
    "**Our New Explorations**\n",
    "\n",
    "- Multiple-action Causal Forest to estimate the counterfactuals(2019,2021 papers)\n",
    "- Sufficient statistics with Covariate Shift Sensivisity Value(This is the idea from a paper proposed by Yuan 2018:sensitivity value)\n",
    "- ...\n",
    "\n",
    "Run the code below that will apply your value estimators to a policy on logged bandit feedback. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03df2936",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TriageEstimator(Policy):\n",
    "    def __init__(self, num_actions=2, num_estimators=2, est_indicator=[]):\n",
    "     self.num_actions=num_actions\n",
    "     self.num_estimators = num_estimators\n",
    "     self.est_assignment = est_indicator\n",
    "    @abc.abstractmethod\n",
    "    \n",
    "    def CompleteCase(X,actions, full_rewards ):\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c6eeeb-6f2e-47c9-af9a-91d123f824d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build our value estimators\n",
    "\n",
    "def get_value_estimators(policy, contexts, actions, rewards, propensities, skip_slow_stuff=False):\n",
    "    \"\"\"   \n",
    "    Args:\n",
    "        policy (Policy): the policy we want to get a value estimate for\n",
    "        contexts (np.array): contexts from bandit feedback\n",
    "        actions (np.array): actions chosen for bandit feedback\n",
    "        rewards (np.array): rewards received in bandit feedback\n",
    "        propensities (np.array): the propensity for each action selected under the logging policy (which is not provided to this function)\n",
    "        skip_slow_stuff (boolean): boolean flag which allows you to turn on/off some slow estimators (ignore this if you like)\n",
    "    Returns:\n",
    "        est (dict): keys are string describing the value estimator, values are the corresponding value estimates \n",
    "    \"\"\"   \n",
    "    ## For IW estimator:\n",
    "    est = {}\n",
    "    #IW estimator:\n",
    "    imp_w = \n",
    "    est[\"mean\"] = np.mean(rewards)\n",
    "    \n",
    "    \n",
    "    ## TODO\n",
    "\n",
    "    return est\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afa3f6c-b2e5-46c0-90af-e27953efa13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimator_stats(estimates, true_parameter_value=None):\n",
    "    \"\"\"\n",
    " \n",
    "     Args:\n",
    "        estimates (pd.DataFrame): each row corresponds to collection of estimates for a sample and\n",
    "            each column corresponds to an estimator\n",
    "        true_parameter_value (float): the true parameter value that we will be comparing estimates to\n",
    "            \n",
    "    Returns:\n",
    "        pd.Dataframe where each row represents data about a single estimator\n",
    "    \"\"\"\n",
    "    \n",
    "    est_stat = []\n",
    "    for est in estimates.columns:\n",
    "        pred_means = estimates[est]\n",
    "        stat = {}\n",
    "        stat['stat'] = est\n",
    "        stat['mean'] = np.mean(pred_means)\n",
    "        stat['SD'] = np.std(pred_means)\n",
    "        stat['SE'] = np.std(pred_means) / np.sqrt(len(pred_means))\n",
    "        if true_parameter_value:\n",
    "            stat['bias'] = stat['mean'] - true_parameter_value\n",
    "            stat['RMSE'] = np.sqrt(np.mean((pred_means - true_parameter_value) ** 2))\n",
    "        est_stat.append(stat)\n",
    "\n",
    "    return pd.DataFrame(est_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9b7592-3e73-4813-9012-405244df920a",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts_test, actions_test, rewards_test, propensities_test = generate_bandit_feedback(contexts=X_test, full_rewards=full_rewards_test, policy=logging_policy, rng=default_rng(6))\n",
    "policy = policy_deterministic\n",
    "est = get_value_estimators(policy, contexts_test, actions_test, rewards_test, propensities_test)\n",
    "policy_true_value = policy.get_value_estimate(X_test, full_rewards_test)\n",
    "print(f\"policy true value {policy_true_value}.\")\n",
    "df = pd.DataFrame(est, index=[0])\n",
    "est"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "51e1a74f-92ff-46cf-b478-2f25e95078fa",
   "metadata": {},
   "source": [
    "**Problem 6.** Run the code below to test your value estimators across multiple trials.  Write a few sentences about anything you learned from these experiments or that you find interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad590855",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials=20\n",
    "val_ests = []\n",
    "policy = policy_deterministic\n",
    "policy_true_value = policy.get_value_estimate(X_test, full_rewards_test)\n",
    "rng=default_rng(6)\n",
    "for i in range(trials):\n",
    "    contexts, actions, rewards, propensities = generate_bandit_feedback(X_test, full_rewards_test, logging_policy, rng=rng)\n",
    "    est = get_value_estimators(policy, contexts, actions, rewards, propensities)\n",
    "    val_ests.append(est)\n",
    "\n",
    "df = pd.DataFrame(val_ests)\n",
    "print(get_estimator_stats(df, true_parameter_value=policy_true_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f034813-be82-491a-9f1d-7337f24b0129",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials=20\n",
    "val_ests = []\n",
    "policy = policy_stochastic\n",
    "policy_true_value = policy.get_value_estimate(X_test, full_rewards_test)\n",
    "rng=default_rng(6)\n",
    "for i in range(trials):\n",
    "    contexts, actions, rewards, propensities = generate_bandit_feedback(X_test, full_rewards_test, logging_policy, rng=rng)\n",
    "    est = get_value_estimators(policy, contexts, actions, rewards, propensities)\n",
    "    val_ests.append(est)\n",
    "\n",
    "df = pd.DataFrame(val_ests)\n",
    "print(get_estimator_stats(df, true_parameter_value=policy_true_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b8a89f-fe78-4fe5-80a6-37026e360193",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials=20\n",
    "val_ests = []\n",
    "policy = uniform_policy\n",
    "policy_true_value = policy.get_value_estimate(X_test, full_rewards_test)\n",
    "rng=default_rng(6)\n",
    "for i in range(trials):\n",
    "    contexts, actions, rewards, propensities = generate_bandit_feedback(X_test, full_rewards_test, logging_policy, rng=rng)\n",
    "    est = get_value_estimators(policy, contexts, actions, rewards, propensities)\n",
    "    val_ests.append(est)\n",
    "\n",
    "df = pd.DataFrame(val_ests)\n",
    "print(get_estimator_stats(df, true_parameter_value=policy_true_value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
