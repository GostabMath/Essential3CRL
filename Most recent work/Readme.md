# Collections of most recent development of Contextual Bandit and Off-policy Evaluation
**Posted by Gostab, NYU**

## *Working Path*
-We will be investigating some work done by one of the most widely cited scholors(Cornell, MIT, and Neflix & Columbia University). The link of all paper work can be found here or the child folder in this working space

### The first scholar we will follow is [Yuta Saito(Click for Google Page)](https://scholar.google.com/citations?user=pw4hwS8AAAAJ&hl=en)

-1. [Unbiased Recommendation Learning From MCNR](https://dl.acm.org/doi/pdf/10.1145/3336191.3371783)

-2  [Open Bandit Database and Pipeline: Reproducible Off-line Policy Evaluation](https://arxiv.org/abs/2008.07146)


