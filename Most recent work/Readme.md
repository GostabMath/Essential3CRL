# Collections of most recent development of Contextual Bandit and Off-policy Evaluation
**Posted by Gostab, NYU**

## *Working Path*
-We will be investigating some work done by one of the most widely cited scholors(Cornell, MIT, and Neflix & Columbia University). The link of all paper work can be found here or the child folder in this working space

### Domain Adaptation and Distribution Shift

|   Author    | Paper         |      Year     |
|-------------| ------------- | ------------- |
|Kun Zhang, etl| Low-Dimensional Density Ratio Estimation|[2019](http://proceedings.mlr.press/v89/stojanov19a/stojanov19a.pdf) |
|              | Density-ratio matching under the Bregman divergence  | [2012](https://www.ism.ac.jp/editsec/aism/pdf/10463_2011_Article_343.pdf) |
|  |Domain Adaptation as a Problem of Inference on Graphical Models  |[2020](https://arxiv.org/pdf/2002.03278.pdf)|
||Domain Adaptation with Invariant Representation Learning: What Transformations to Learn?|[2021](https://proceedings.neurips.cc/paper/2021/file/cfc5d9422f0c8f8ad796711102dbe32b-Paper.pdf)
|Yuta,Saito|Causal Embedding for Recommendation|[2018](https://arxiv.org/pdf/1706.07639)|
||Domain Adversarial Matrix Factorization|[2022](https://usaito.github.io/files/IJCAI2022_DAMF.pdf)


### Off-line Reinforcement Learning 
[*Minmin Chen, Yuta Saito, Longqi Yang*]

[Yuta Saito(Click for Google Page)](https://scholar.google.com/citations?user=pw4hwS8AAAAJ&hl=en)

|   Author    | Paper         |      Year     |
|-------------| ------------- | ------------- |
|| Unbiased Recommendation Learning From MCNR |[2020](https://dl.acm.org/doi/pdf/10.1145/3336191.3371783)  |
|| Open Bandit Database and Pipeline: Reproducible Off-line Policy Evaluation  |[2022](https://arxiv.org/abs/2008.07146)|



