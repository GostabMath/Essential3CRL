# Collections of most recent development of Contextual Bandit and Off-policy Evaluation
**Posted by Gostab, NYU**

## *Working Path*
-We will be investigating some work done by one of the most widely cited scholors(Cornell, MIT, and Neflix & Columbia University). The link of all paper work can be found here or the child folder in this working space

### Domain Adaptation and Distribution Shift

|   Author    | Paper         |      Year     |
|-------------| ------------- | ------------- |
|Kun Zhang, etl| Low-Dimensional Density Ratio Estimation for Covariate Shift Correction | [2019](https://arxiv.org/pdf/2002.03278.pdf)  |
|              | Density-ratio matching under the Bregman divergence  | [2012](https://www.ism.ac.jp/editsec/aism/pdf/10463_2011_Article_343.pdf) |




### Off-line Reinforcement Learning 
[*Minmin Chen, Yuta Saito, Longqi Yang*]

[Yuta Saito(Click for Google Page)](https://scholar.google.com/citations?user=pw4hwS8AAAAJ&hl=en)

|   Author    | Paper         |      Year     |
|-------------| ------------- | ------------- |
|| Unbiased Recommendation Learning From MCNR |[2020](https://dl.acm.org/doi/pdf/10.1145/3336191.3371783)  |
|| Open Bandit Database and Pipeline: Reproducible Off-line Policy Evaluation  |[2022](https://arxiv.org/abs/2008.07146)|



