{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy learning and Off-line policy evaluation\n",
    "\n",
    "## Domain Adaptation: A perspective from Sensitivity Value: measurable covariates shift\n",
    "\n",
    "\n",
    "- Edited and Completed : Jiaxu Ren\n",
    "\n",
    "This code sample refers to some sub-domains of my research area: off-line policy reinforcement learning and domain adaptation.\n",
    "the full doman adaptation expetiments can be seen in my Github repository: 3CRL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "import abc\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "First we define the relevant data and policy objects and load a dataset based on the UCI Letter classification data.\n",
    "\n",
    "4 parts:\n",
    "\n",
    "**Learning a policy by learning a linear reward model (direct method)*\n",
    "\n",
    "- This is done by me first. The direct method is to impute the missing(unobserved data). See we used the linear model to impute the rewards-however, the results are pretty off the right track because we are creating the simulation data just by using some overly randomized formulus. That indicates the linear parametric assumption does not hold perhaps.\n",
    "\n",
    "Then we change our model to sigmoid, which seems better to fit the reward.\n",
    "    \n",
    "**Learning a policy by learning a log-linear policy model (IW, clipping, POEM)**\n",
    "\n",
    "- \n",
    "    \n",
    "**Considering the effects of model size with neural network models**\n",
    "\n",
    "- \n",
    "    \n",
    "**Comparing the various algorithms on different datasets**\n",
    "\n",
    "- \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note 1: Since we are using a classification dataset and converting it to a simulated bandit problem, we have access to the full reward vectors. We will split the data into train, val, and test sets. The train and val sets will not have access to the full rewards, but to reduce variance of the evaluation we will allow access to the full rewards on the test set. Note this is something we can do in this semi-synthetic data setting, but not something that can usually be done in the real world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note 2: This Document uses pytorch throughout. We have tried to avoid requiring you to fill in the more complicated parts (defining the models and training loops). But, if you are unfamiliar with pytorch it is worth going through this brief tutorial (https://pytorch.org/tutorials/beginner/basics/intro.html) and taking a look at the docs for any specific questions (https://pytorch.org/docs/stable/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instruction Space\n",
    "To generalize the work we will be doing:\n",
    "To do the simulation(the real data we get in the world), we need to generate the bandit feedback from the total feecback\n",
    "This is done by the first function we will create. However, to generate bandit feedback, we also need a known policy because a bandit feedback is obtained by a policy we have played. Therefore the the **Bandit Feedback** function contains a policy function that selects action for us. \n",
    "\n",
    "Next, we have dataloader that helps us produce the data set for training,validation and test, respectively. Using this function, we also finish spliting the dataset. By randomly labling the data, we send **Bandit Feedback** to this function and take arguments such as policy type and data label to finally generate data we will be using for evaluation.\n",
    "\n",
    "Until now, we are about to finish the local data pipeline and ready for train the data.\n",
    "we have training data obtained from 2 defined functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevant Objects\n",
    "\n",
    "The below code defines the objects that we need for the rest of the assignment to handle data and policies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BanditDataset:\n",
    "    \"\"\"\n",
    "        Dataset object to simulate offline bandit feedback from \n",
    "        a classification dataset (X,y) and logging policy\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, n_actions, logging_policy, \n",
    "                 seed=0):\n",
    "        self.rng = default_rng(seed)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n_actions = n_actions\n",
    "        self.n_data = len(y)\n",
    "        self.logging_policy = logging_policy\n",
    "        \n",
    "        # compute rewards\n",
    "        self.full_rewards = 0.1 * np.ones((self.n_data, self.n_actions))\n",
    "        for i in range(self.n_data):\n",
    "            self.full_rewards[i,self.y[i]] = 0.9\n",
    "        \n",
    "        # sample actions from logging policy\n",
    "        self.actions, self.probs = self.logging_policy.select_actions(self.X, self.rng)\n",
    "            \n",
    "        # compute rewards\n",
    "        self.rewards = self.full_rewards[np.arange(self.n_data), self.actions]\n",
    "        \n",
    "    def sample_batch(self, batch_size):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            batch_size (int): size of batch to be sampled\n",
    "        Returns:\n",
    "            tuple of (contexts, actions, rewards, probs) of shapes\n",
    "                    contexts: (batch_size, context_dim)\n",
    "                    actions: (batch_size, )\n",
    "                    rewards: (batch_size, )\n",
    "                    probs: (batch_size, )\n",
    "        \"\"\"\n",
    "        idx = self.rng.choice(self.n_data, size=batch_size)\n",
    "        contexts = torch.tensor(self.X[idx], dtype=torch.float32)\n",
    "        actions = torch.tensor(self.actions[idx], dtype=torch.int64)\n",
    "        rewards = torch.tensor(self.rewards[idx], dtype=torch.float32)\n",
    "        probs = torch.tensor(self.probs[idx], dtype=torch.float32)\n",
    "        return contexts, actions, rewards, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(logging_name, train_size=2000):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            logging_name (str): name of the logging policy to be used\n",
    "            train (bool): whether this is the train or test set\n",
    "        Returns:\n",
    "            BanditDataset based on UCI Letter data with the relevant logging policy \n",
    "    \"\"\"\n",
    "    assert train_size < 10001\n",
    "    \n",
    "    # load classification data\n",
    "    df = pd.read_csv('data/letter-recognition.data', header=None)\n",
    "    y = np.array([ord(l) - 65 for l in df[0]])\n",
    "    X = np.array(df[list(range(1,17))])\n",
    "    \n",
    "    # split data\n",
    "    X_train = X[:train_size]\n",
    "    y_train = y[:train_size]\n",
    "    X_val = X[-10000:-9000]\n",
    "    y_val = y[-10000:-9000]\n",
    "    X_test = X[-9000:]\n",
    "    y_test = y[-9000:]\n",
    "\n",
    "    # load policy\n",
    "    if logging_name == 'logistic':\n",
    "        lr = LogisticRegression(multi_class='multinomial', solver='sag', max_iter=10)\n",
    "        n = 1000\n",
    "        lr.fit(X_train[:n], y_train[:n])\n",
    "        policy = PolicyModelPolicy(lr, 26)\n",
    "    elif logging_name == 'uniform':\n",
    "        policy = UniformPolicy(26)\n",
    "    else:\n",
    "        raise NotImplemented\n",
    "        \n",
    "    # create bandit datasets\n",
    "    train_data = BanditDataset(X_train, y_train, 26, policy)\n",
    "    val_data = BanditDataset(X_val, y_val, 26, policy)\n",
    "    test_data = BanditDataset(X_test, y_test, 26, policy)\n",
    "        \n",
    "    # remove access to labels for train and val\n",
    "    train_data.full_reward = None\n",
    "    train_data.y = None\n",
    "    val_data.full_reward = None\n",
    "    val_data.y = None\n",
    "        \n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy:\n",
    "    def __init__(self, num_actions=2):\n",
    "        self.num_actions = num_actions\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_action_distribution(self, X):\n",
    "        \"\"\"   \n",
    "        This method is intended to be overridden by each implementation of Policy.\n",
    "\n",
    "        Args:\n",
    "            X (pd.DataFrame): contexts\n",
    "\n",
    "        Returns:\n",
    "            2-dim numpy array with the same number of rows as X and self.num_actions columns. \n",
    "                Each rows gives the policy's probability distribution over actions conditioned on the context in the corresponding row of X\n",
    "        \"\"\"   \n",
    "        raise NotImplementedError(\"Must override method\")\n",
    "\n",
    "    def get_action_propensities(self, X, actions):\n",
    "        \"\"\"   \n",
    "        Args:\n",
    "            X (pd.DataFrame): contexts, rows correspond to entries of actions\n",
    "            actions (np.array): actions taken, represented by integers, corresponding to rows of X\n",
    "\n",
    "        Returns:\n",
    "            1-dim numpy array of probabilities (same size as actions) for taking each action in its corresponding context\n",
    "        \"\"\"   \n",
    "        dist = self.get_action_distribution(X)\n",
    "        n = X.shape[0]\n",
    "        action_probs = dist[np.arange(n), actions ]\n",
    "        return action_probs\n",
    "\n",
    "    def select_actions(self, X, rng=default_rng(1)):\n",
    "        \"\"\"   \n",
    "        Args:\n",
    "            X (pd.DataFrame): contexts, rows correspond to entries of actions and propensities returned\n",
    "\n",
    "        Returns:\n",
    "            actions (np.array): 1-dim numpy array of length equal to the number of rows of X.  Each entry is an integer indicating the action selected for the corresponding context in X. \n",
    "                The action is selected randomly according to the policy, conditional on the context specified in the appropriate row of X.\n",
    "            propensities (np.array): 1-dim numpy array of length equal to the number of rows of X; gives the propensity for each action selected in actions\n",
    "\n",
    "        \"\"\"   \n",
    "        dist = self.get_action_distribution(X)\n",
    "        n = X.shape[0]\n",
    "        cdf = np.cumsum(dist, axis=1)\n",
    "        tiled = np.tile(rng.random([n,1]), [1, self.num_actions])\n",
    "        actions = np.argmax(tiled <= cdf, axis=1)\n",
    "        propensities = dist[np.arange(n), actions]\n",
    "        return actions, propensities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniformPolicy(Policy):\n",
    "    \"\"\"\n",
    "        Uniformly random policy\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_actions=2):\n",
    "        self.num_actions = num_actions\n",
    "\n",
    "    def get_action_distribution(self, X):\n",
    "        action_distribution = np.full([X.shape[0], self.num_actions], 1/self.num_actions)\n",
    "        return action_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyModelPolicy(Policy):\n",
    "    \"\"\"\n",
    "        Policy based on a policy_model that has a predict_proba method\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, policy_model, num_actions, deterministic=False):\n",
    "        self.num_actions = num_actions\n",
    "        self.model = policy_model\n",
    "        self.deterministic = deterministic\n",
    "        \n",
    "    def get_action_distribution(self, X):\n",
    "        probs = self.model.predict_proba(X)\n",
    "        \n",
    "        if self.deterministic:\n",
    "            probs = torch.tensor(probs)\n",
    "            probs = nn.functional.one_hot(torch.argmax(probs, dim=1), \n",
    "                                          self.num_actions).detach().numpy()\n",
    "            \n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RewardModelPolicy(Policy):\n",
    "    \"\"\"\n",
    "        Policy based on a reward_model that has a predict method\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, reward_model, num_actions):\n",
    "        self.num_actions = num_actions\n",
    "        self.model = reward_model\n",
    "        \n",
    "    def get_action_distribution(self, X):\n",
    "        preds = self.model.predict(X)\n",
    "        preds = torch.tensor(preds)\n",
    "        probs = nn.functional.one_hot(torch.argmax(preds, dim=1), \n",
    "                                          self.num_actions).detach().numpy()\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(loss):\n",
    "    \"\"\"\n",
    "        Function to plot smoothed learning curves\n",
    "    \"\"\"\n",
    "    plt.plot(smooth(loss))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('step')\n",
    "    plt.show()\n",
    "\n",
    "def smooth(arr, gamma = 0.9):\n",
    "    new_arr = [arr[0]]\n",
    "    for x in arr[1:]:\n",
    "        new_arr.append(gamma * new_arr[-1] + (1-gamma) * x)\n",
    "    return np.array(new_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_full_feedback(policy, dataset):\n",
    "    \"\"\"\n",
    "        Function to evaluate policy on a test dataset that has full_rewards\n",
    "        \n",
    "        Args:\n",
    "            policy (Policy): the policy to be evaluated\n",
    "            dataset (BanditDataset): the dataset to use for evaluation (i.e. the test set)\n",
    "        Returns:\n",
    "            real-valued value estimate\n",
    "    \"\"\"\n",
    "    action_probs = policy.get_action_distribution(dataset.X)\n",
    "    expected_reward_per_context = np.sum(dataset.full_rewards * action_probs, axis=1)\n",
    "    value_est = np.mean(expected_reward_per_context)\n",
    "    \n",
    "    return value_est\n",
    "\n",
    "def evaluate_sniw(policy, dataset):\n",
    "    \"\"\"\n",
    "        Function to evaluate policy on a validation dataset\n",
    "        Uses a self-normalized estimator\n",
    "        \n",
    "        Args:\n",
    "            policy (Policy): the policy to be evaluated\n",
    "            dataset (BanditDataset): the dataset to use for evaluation (i.e. the validation set)\n",
    "        Returns:\n",
    "            real-valued value estimate\n",
    "    \"\"\"\n",
    "    action_probs = policy.get_action_propensities(dataset.X, dataset.actions)\n",
    "    weights = action_probs / dataset.probs\n",
    "\n",
    "    value_est = np.sum(weights * dataset.rewards) / np.sum(weights)\n",
    "    \n",
    "    return value_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_actions = 26\n",
    "context_dim = 16\n",
    "\n",
    "log_type = 'logistic'\n",
    "train_size = 2000\n",
    "\n",
    "train_data, val_data, test_data = load_data(log_type, train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: direct method(Reg_imput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the reward model\n",
    "\n",
    "First we need a reward model. Here we implement a linear model in pytorch. We could use SKLearn for the linear model, but we will need to use gradient-based optimization later on for policy learning and to use neural models, so instead we will use pytorch throughout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRewardModel(nn.Module):\n",
    "    def __init__(self, context_dim, n_actions):\n",
    "        super(LinearRewardModel, self).__init__()\n",
    "        self.linear = nn.Linear(context_dim, n_actions)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "            Args: \n",
    "                X (torch.tensor): a tensor of shape (batch_size, context_dim) and dtype torch.float32\n",
    "            Returns:\n",
    "                a torch.tensor of shape (batch_size, n_actions) containing model predictions\n",
    "        \"\"\"\n",
    "        #preds = self.linear(X)\n",
    "        preds = torch.sigmoid(self.linear(X))\n",
    "        return preds\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "            Args: \n",
    "                X (np.ndarray): an array of shape (batch_size, context_dim)\n",
    "            Returns:\n",
    "                np.ndarray of shape (batch_size, n_actions) containing model predictions\n",
    "        \"\"\"\n",
    "        #X = torch.tensor(X, dtype=torch.float32)\n",
    "        return self.forward(X).detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the training loop\n",
    "\n",
    "Since we are using pytorch, we need to define our own training loop. Here we will use the adam optimizer, a variant of SGD (https://pytorch.org/docs/stable/generated/torch.optim.Adam.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, dataset, hyperparams):\n",
    "    \"\"\"\n",
    "        Args: \n",
    "            model (nn.Module): a pytorch model with a forward method that takes contexts\n",
    "            loss_fn (function): a function that takes torch.tensors of (preds, actions, rewards, propensities) \n",
    "                and returns a scalar torch.tensor loss\n",
    "            dataset (BanditDataset): the training set\n",
    "            hyperparams (dict): a dict of hyperparameter values. \n",
    "                    Needs to at least contain:\n",
    "                        n_steps (int): the number of gradient steps to take\n",
    "                        batch_size (int): the batch size for sampling SGD minibatches\n",
    "                        lr (float): the learning rate for the adam optimizer\n",
    "        Returns:\n",
    "            list of training loss on each batch\n",
    "    \"\"\"\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=hyperparams['lr'])\n",
    "    \n",
    "    losses = []\n",
    "    for step in tqdm(range(hyperparams['n_steps'])):\n",
    "        contexts, actions, rewards, propensities = dataset.sample_batch(hyperparams['batch_size'])\n",
    "        loss = loss_fn(model.predict(contexts), actions, rewards, propensities, hyperparams)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a: defining the learning objective\n",
    "\n",
    "We will define the loss function for the direct method. The function takes in a batch (preds, actions, rewards, propensities) and returns a scalar tensor for the loss on this batch. Please note some inputs are in the form of *tensor* while some of *array*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dm_loss(preds, actions, rewards, propensities, hyperparams):\n",
    "       \"\"\"\n",
    "       Arg:\n",
    "       preds: this is the imputed reward for each action under context X. Please remember this preds include full-imputed reward.\n",
    "       actions: this is the actions vector taken by the policy we played in model argument\n",
    "       rewards: this is the vector of observed rewards. \n",
    "       propensites: this is the vector of propensities of taken actions\n",
    "       \n",
    "       \"\"\"\n",
    "       actions = actions.numpy()\n",
    "       rewards = rewards.numpy()\n",
    "       propensities = propensities.numpy()\n",
    "       preds = preds[range(hyperparams[\"batch_size\"]),actions]\n",
    "       estimated_dm_reward = np.matmul(preds,propensities)\n",
    "       #estimated_dm_reward = preds*np.array(propensities)\n",
    "       estimated_dm_loss = np.mean(np.square(estimated_dm_reward-rewards))/hyperparams['batch_size']\n",
    "       estimated_dm_loss = torch.tensor(estimated_dm_loss,dtype=torch.float32,requires_grad=True)\n",
    "       #return preds\n",
    "       return estimated_dm_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9, 0.1, 0.9, 0.1], dtype=float32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparams = {\"n_steps\":500,\"batch_size\":4,\"lr\":0.01}\n",
    "contexts, actions, rewards, propensities = train_data.sample_batch(hyperparams['batch_size'])\n",
    "preds = LinearRewardModel(context_dim=context_dim,n_actions=num_actions)\n",
    "preds = preds.predict(contexts)\n",
    "preds.shape\n",
    "preds\n",
    "preds[range(hyperparams['batch_size']),actions]\n",
    "rewards.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dm_loss(LinearRewardModel(context_dim=context_dim,n_actions=num_actions),train_data.sample_batch(hyperparams['batch_size']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b: learning a policy\n",
    "\n",
    "Now use the training loop to train the LinearRewardModel. Plot the learning curve with plot_loss. Then use evaluate_sniw and the validation set to estimate the value of the deterministic policy corresponding to the reward model you trained.\n",
    "In the real-world case, we can try multiple different fitting models to see the results.Some further exploration might include: causal forest, recursive partitioning. \n",
    "\n",
    "But the underlying logic and machinary remains the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 5318.25it/s]\n"
     ]
    }
   ],
   "source": [
    "dm_lp = train(model=LinearRewardModel(context_dim=context_dim,n_actions=num_actions),loss_fn=dm_loss,dataset=train_data,hyperparams=hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(dm_lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6184000000000001"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_model = LogisticRegression(multi_class='multinomial', solver='sag', max_iter=10).fit(val_data.X,val_data.actions)\n",
    "played_policy = PolicyModelPolicy(policy_model=policy_model,num_actions=num_actions,deterministic=True)\n",
    "evaluate_sniw(policy=played_policy,dataset=val_data)\n",
    "evaluate_full_feedback(policy=played_policy,dataset=val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part c: tuning the hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the validation set and the evaluate_sniw function defined above, you can tune the hyperparameters of the training loop including the number of steps, batch_size, and learning rate. Try some different settings and report your results. (Hint: try training for longer) \n",
    "\n",
    "Then after tuning on the validation set, report the value on the test set using the evaluate_full_feedback function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
