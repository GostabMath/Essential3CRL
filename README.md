# Knowledge Map: Essential3CRL

>Essential3CRL is short for **Essential Counterfactual/Causal/Core Reinforcement Learning**. Essential3CRL is a comprehensive documentation that delves into the world of causal machine learning. Our goal is to cover both the most classic methods and the latest advancements in Off-line Reinforcement Learning, Contextual Bandit Feedback, and Domain Adaptation Under Distribution Shift.

<img src="https://github.com/GostabMath/Essential3CRL/blob/main/icons/Category.png">
As of now, this document is under active development, and we are committed to continually expanding its content. We strongly believe that Essential3CRL will be a valuable resource for researchers and practitioners interested in causal machine learning, and we are excited to share our progress with you. Your expertise and insights would be immensely valuable to us as we continue to develop this documentation. This is a document under active development and some materials are a finer,detailed expansion of two subsections of the work done by [Ruocheng Guo](https://github.com/rguo12/
awesome-causality-algorithms), a principal researcher at ByteDance,UK. 

<hr>

We hope the resource expedites your study and strengthens your grasp of causality, counterfactuals, and domain adaptation. As you are particularly interested in counterfactual learning and bandit-based recommendation systems, we believe this document will prove to be a valuable asset. While it may not cover every aspect of the vast causal world, it is tailored to provide a focused exploration of your central interests.

**Thank you for showing interest in our work on causal inference, and we eagerly anticipate your thoughts on Essential3CRL.**

Topics will include:

## Basic of Counterfactual Learning:

|   Field     | Publication   | Year          |
|-------------| ------------- | ------------- |
|Causal Machine Learning|Causal Machine Learning:A Survey and Open Problems|[2022](https://arxiv.org/pdf/2206.15475.pdf)|

Here is a direct link to counterfactual learning course taught by Professor Thorsten, a famous researcher at Cornell University.

- Hacking Course: [Counterfactual Machine Learning](https://github.com/GostabMath/EssentialsCausalLearning/tree/main/Counterfactual%20Machine%20Learning/Lectures)


## Reinforcement Learning:

### Off-line Reinforcement Learning

Off-line reinforcement learning has been widely used in recommendation systems and contextual bandit for off-policy evaluation. I will follow papers that mark the most recent advancement of this field and do some sample-based implementation; I will also try my best to make some direct tie-ins and connect each method in terms of my personal understanding. 

- Start your 3CRL journey with basic knowledge of distribution shift and domain adaptation:[Essential3CRL/Fundamental](https://github.com/GostabMath/Essential3CRL/tree/main/Fundamental)
- See some most recent contributions and advancement: [Essential3CRL/Most recent work](https://github.com/GostabMath/Essential3CRL/tree/main/Most%20recent%20work)

### Off-policy Reinoforcement Learning

  TBD

### Online Reinforcement Learning

- TBD

## Causal Dicovery and Graphic Discovery:

this topic does not quite match the conventional framework **Potential Outcome** mainly used in observational study by Rubin. Therefore, please visit another repository I build to start your journey of DAGs and Graphical Causality Discovery.
