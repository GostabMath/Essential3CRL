# Knowledge Map: Essential3CRL

>Essential3CRL is short for **Essential Counterfactual/Causal/Core Reinforcement Learning**. Essential3CRL is a comprehensive documentation that delves into the world of causal machine learning. Our goal is to cover both the most classic methods and the latest advancements in Off-line Reinforcement Learning, Contextual Bandit Feedback, and Domain Adaptation Under Distribution Shift.

As of now, this document is under active development, and we are committed to continually expanding its content. We strongly believe that Essential3CRL will be a valuable resource for researchers and practitioners interested in causal machine learning, and we are excited to share our progress with you. Your expertise and insights would be immensely valuable to us as we continue to develop this documentation. This is a document under active development and some materials are a finer,detailed expansion of two subsections of the work done by [Ruocheng Guo](https://github.com/rguo12/
awesome-causality-algorithms), a principal researcher at ByteDance,UK. 

<hr>

We hope these materials can speed up your study and "reinforce" your understanding of causality, counterfactuals, and domain adaptation. Because my central interest is counterfactual learning and bandit-based recommendation system, this document might not be a thorough reflection of anything you have seen in the causal world. Advice and commentes are welcome. Thank you for your interest in causal inference.

Topics will include:

## Basic of Counterfactual Learning:

|   Field     | Publication   | Year          |
|-------------| ------------- | ------------- |
|Causal Machine Learning|Causal Machine Learning:A Survey and Open Problems|[2022](https://arxiv.org/pdf/2206.15475.pdf)|

Here is a direct link to counterfactual learning course taught by Professor Thorsten, a famous researcher at Cornell University.

- Hacking Course: [Counterfactual Machine Learning](https://github.com/GostabMath/EssentialsCausalLearning/tree/main/Counterfactual%20Machine%20Learning/Lectures)


## Off-line Reinforcement Learning:

Off-line reinforcement learning has been widely used in recommendation systems and contextual bandit for off-policy evaluation. I will follow papers that mark the most recent advancement of this field and do some sample-based implementation; I will also try my best to make some direct tie-ins and connect each method in terms of my personal understanding.

- Start your 3CRL journey with basic knowledge of distribution shift and domain adaptation:[Essential3CRL/Fundamental](https://github.com/GostabMath/Essential3CRL/tree/main/Fundamental)
- See some most recent contributions and advancement: [Essential3CRL/Most recent work](https://github.com/GostabMath/Essential3CRL/tree/main/Most%20recent%20work)

## Causal Dicovery and Graphic Discovery:

this topic does not quite match the conventional framework **Potential Outcome** mainly used in observational study by Rubin. Therefore, please visit another repository I build to start your journey of DAGs and Graphical Causality Discovery.
